{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherited: `data` \n",
    "#%run \"C:\\Users\\Asus\\Desktop\\Coding\\API_Flask\\side_BenckMark\\embedding_Workspace\\bench\\2_Preprocess.ipynb\" \n",
    "\n",
    "import dill\n",
    "# Load session \n",
    "dill.load_session('embedded_Data.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>combined</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "      <th>review_Embedding</th>\n",
       "      <th>semantic_Label</th>\n",
       "      <th>label_Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B003XPF9BO</td>\n",
       "      <td>A3R7JR3FMEBXQB</td>\n",
       "      <td>5</td>\n",
       "      <td>where does one  start...and stop... with a tre...</td>\n",
       "      <td>Wanted to save some to bring to my Chicago fam...</td>\n",
       "      <td>Title: where does one  start...and stop... wit...</td>\n",
       "      <td>52</td>\n",
       "      <td>[0.007018072064965963, -0.02731654793024063, 0...</td>\n",
       "      <td>[0.007018072064965963, -0.02731654793024063, 0...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.006508708465844393, -0.008743545040488243,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297</td>\n",
       "      <td>B003VXHGPK</td>\n",
       "      <td>A21VWSCGW7UUAR</td>\n",
       "      <td>4</td>\n",
       "      <td>Good, but not Wolfgang Puck good</td>\n",
       "      <td>Honestly, I have to admit that I expected a li...</td>\n",
       "      <td>Title: Good, but not Wolfgang Puck good; Conte...</td>\n",
       "      <td>178</td>\n",
       "      <td>[-0.003140551969408989, -0.009995664469897747,...</td>\n",
       "      <td>[-0.003140551969408989, -0.009995664469897747,...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.006508708465844393, -0.008743545040488243,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   ProductId          UserId  Score  \\\n",
       "0           0  B003XPF9BO  A3R7JR3FMEBXQB      5   \n",
       "1         297  B003VXHGPK  A21VWSCGW7UUAR      4   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  where does one  start...and stop... with a tre...   \n",
       "1                   Good, but not Wolfgang Puck good   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Wanted to save some to bring to my Chicago fam...   \n",
       "1  Honestly, I have to admit that I expected a li...   \n",
       "\n",
       "                                            combined  n_tokens  \\\n",
       "0  Title: where does one  start...and stop... wit...        52   \n",
       "1  Title: Good, but not Wolfgang Puck good; Conte...       178   \n",
       "\n",
       "                                           embedding  \\\n",
       "0  [0.007018072064965963, -0.02731654793024063, 0...   \n",
       "1  [-0.003140551969408989, -0.009995664469897747,...   \n",
       "\n",
       "                                    review_Embedding semantic_Label  \\\n",
       "0  [0.007018072064965963, -0.02731654793024063, 0...       positive   \n",
       "1  [-0.003140551969408989, -0.009995664469897747,...       positive   \n",
       "\n",
       "                                     label_Embedding  \n",
       "0  [-0.006508708465844393, -0.008743545040488243,...  \n",
       "1  [-0.006508708465844393, -0.008743545040488243,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Predictions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Main Calculations` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Setup` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Classification Report` \n",
    "* methods: \"`create_Report`\", \"`extract_summary_metrics`\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Report(current_Prediction):\n",
    "    global cosine_Report \n",
    "    \n",
    "    # Get the classification report with zero_division=1 to handle division by zero\n",
    "    report = classification_report(data[\"semantic_Label\"], data[current_Prediction], zero_division=1)\n",
    "    \n",
    "    title_List, precision_List, recall_List, f1_List, support_List = [], [], [], [], [] \n",
    "\n",
    "    for line in report.split(\"\\n\")[2:-5]:  # Skip the first two lines and the last five lines of the report\n",
    "        try:\n",
    "            # Split the line by spaces but exclude empty splits\n",
    "            values = [value for value in line.split(\"  \") if value]\n",
    "            \n",
    "            title, precision, recall, f1, support = values\n",
    "            title_List.append(title.strip())\n",
    "            precision_List.append(float(precision))\n",
    "            recall_List.append(float(recall))\n",
    "            f1_List.append(float(f1))\n",
    "            support_List.append(int(support))\n",
    "        except:\n",
    "            pass \n",
    "\n",
    "    # Create dataframe from the values \n",
    "    cosine_Report = pd.DataFrame({\n",
    "        'title': title_List, \n",
    "        'precision': precision_List, \n",
    "        'recall': recall_List, \n",
    "        'f1': f1_List, \n",
    "        'support': support_List\n",
    "    })    \n",
    "    \n",
    "    return cosine_Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary_metrics(current_Prediction):\n",
    "    # Get the classification report with zero_division=1 to handle division by zero\n",
    "    report = classification_report(data[\"semantic_Label\"], data[current_Prediction], zero_division=1)\n",
    "    \n",
    "    # Split the report by lines\n",
    "    lines = report.split(\"\\n\")\n",
    "    \n",
    "    # Extract accuracy\n",
    "    try:\n",
    "        accuracy = float(lines[-2].split(\":\")[1].strip())\n",
    "    except:\n",
    "        accuracy = float('NaN')\n",
    "    \n",
    "    # Extract macro avg metrics\n",
    "    macro_avg = lines[-4].split()\n",
    "    try:\n",
    "        macro_precision = float(macro_avg[2])\n",
    "    except:\n",
    "        macro_precision = float('NaN')\n",
    "    try:\n",
    "        macro_recall = float(macro_avg[3])\n",
    "    except:\n",
    "        macro_recall = float('NaN')\n",
    "    try:\n",
    "        macro_f1 = float(macro_avg[4])\n",
    "    except:\n",
    "        macro_f1 = float('NaN')\n",
    "    try:\n",
    "        macro_support = int(macro_avg[5])\n",
    "    except:\n",
    "        macro_support = float('NaN')\n",
    "    \n",
    "    # Extract weighted avg metrics\n",
    "    weighted_avg = lines[-3].split()\n",
    "    try:\n",
    "        weighted_precision = float(weighted_avg[2])\n",
    "    except:\n",
    "        weighted_precision = float('NaN')\n",
    "    try:\n",
    "        weighted_recall = float(weighted_avg[3])\n",
    "    except:\n",
    "        weighted_recall = float('NaN')\n",
    "    try:\n",
    "        weighted_f1 = float(weighted_avg[4])\n",
    "    except:\n",
    "        weighted_f1 = float('NaN')\n",
    "    try:\n",
    "        weighted_support = int(weighted_avg[5])\n",
    "    except:\n",
    "        weighted_support = float('NaN')\n",
    "    \n",
    "    # Create a DataFrame with the extracted metrics\n",
    "    summary_df = pd.DataFrame({\n",
    "        'title': ['accuracy', 'macro avg', 'weighted avg'],\n",
    "        'precision': [float('NaN'), macro_precision, weighted_precision],\n",
    "        'recall': [float('NaN'), macro_recall, weighted_recall],\n",
    "        'f1': [float('NaN'), macro_f1, weighted_f1],\n",
    "        'support': [accuracy, macro_support, weighted_support]\n",
    "    })\n",
    "    \n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Similarity Calculations`\n",
    "* method: \"`label_Similarity_Score`\", \"`predict_1`\", \"`predict_2`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def label_Similarity_Score(review_embedding, label_embeddings, method='Cosine'):\n",
    "    scores = {}\n",
    "    \n",
    "    for label, embedding in label_embeddings.items():\n",
    "        if method == 'Cosine':\n",
    "            scores[label] = 1 - distance.cosine(review_embedding, embedding)\n",
    "        elif method == 'Euclidean':\n",
    "            scores[label] = 1 / (1 + distance.euclidean(review_embedding, embedding))\n",
    "        elif method == 'Manhattan':\n",
    "            scores[label] = 1 / (1 + distance.cityblock(review_embedding, embedding))\n",
    "        elif method == 'Minkowski':\n",
    "            scores[label] = 1 / (1 + distance.minkowski(review_embedding, embedding, p=3))\n",
    "        elif method == 'Pearson':\n",
    "            scores[label] = np.corrcoef(review_embedding, embedding)[0, 1] # Pearson is not a distance metric, so we use correlation coefficient instead \n",
    "        elif method == 'Canberra':\n",
    "            scores[label] = 1 / (1 + distance.canberra(review_embedding, embedding))\n",
    "       \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def predict_1(similarity_scores, n=2):\n",
    "    # Sort labels based on scores and get the top n labels\n",
    "    sorted_labels = sorted(similarity_scores, key=similarity_scores.get, reverse=True)\n",
    "    return sorted_labels[:n][0]\n",
    "\n",
    "def predict_2(scores):\n",
    "    max_index = np.argmax(scores)\n",
    "    if max_index < len(current_Labels):\n",
    "        return current_Labels[max_index]\n",
    "    else:\n",
    "        return 'External'  # or any other placeholder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Process` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Similarities & Predictions` \n",
    "* Output: \"`Probabilities`\" & \"`Labels`\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Similarity_Score for each review\n",
    "data[\"Similarity_Score_Cosine\"]    = data[\"review_Embedding\"].apply(lambda x: label_Similarity_Score(x, label_Dict, method='Cosine')) \n",
    "data[\"Similarity_Score_Euclidean\"] = data[\"review_Embedding\"].apply(lambda x: label_Similarity_Score(x, label_Dict, method='Euclidean')) \n",
    "data[\"Similarity_Score_Manhattan\"] = data[\"review_Embedding\"].apply(lambda x: label_Similarity_Score(x, label_Dict, method='Manhattan')) \n",
    "data[\"Similarity_Score_Minkowski\"] = data[\"review_Embedding\"].apply(lambda x: label_Similarity_Score(x, label_Dict, method='Minkowski')) \n",
    "data[\"Similarity_Score_Pearson\"]   = data[\"review_Embedding\"].apply(lambda x: label_Similarity_Score(x, label_Dict, method='Pearson')) \n",
    "data[\"Similarity_Score_Canberra\"]  = data[\"review_Embedding\"].apply(lambda x: label_Similarity_Score(x, label_Dict, method='Canberra')) \n",
    "\n",
    "# Assign top 2 labels for each review \n",
    "data[\"predicted_labels_Cosine\"]    = data[\"Similarity_Score_Cosine\"].apply(lambda x: predict_1(x, 1))\n",
    "data[\"predicted_labels_Euclidean\"] = data[\"Similarity_Score_Euclidean\"].apply(lambda x: predict_1(x, 1))\n",
    "data[\"predicted_labels_Manhattan\"] = data[\"Similarity_Score_Manhattan\"].apply(lambda x: predict_1(x, 1))\n",
    "data[\"predicted_labels_Minkowski\"] = data[\"Similarity_Score_Minkowski\"].apply(lambda x: predict_1(x, 1))\n",
    "data[\"predicted_labels_Pearson\"]   = data[\"Similarity_Score_Pearson\"].apply(lambda x: predict_1(x, 1))\n",
    "data[\"predicted_labels_Canberra\"]  = data[\"Similarity_Score_Canberra\"].apply(lambda x: predict_1(x, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Report` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Process:` Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count values \n",
    "count_Cosine    = data[\"predicted_labels_Cosine\"].value_counts() \n",
    "count_Euclidean = data[\"predicted_labels_Euclidean\"].value_counts() \n",
    "count_Manhattan = data[\"predicted_labels_Manhattan\"].value_counts() \n",
    "count_Minkowski = data[\"predicted_labels_Minkowski\"].value_counts()  \n",
    "count_Pearson = data[\"predicted_labels_Pearson\"].value_counts()  \n",
    "count_Canberra = data[\"predicted_labels_Canberra\"].value_counts()  \n",
    "# Total\n",
    "count_Combined  = pd.DataFrame({\"Cosine\": count_Cosine.values,       \"Euclidean\": count_Euclidean.values, \n",
    "                                \"Manhattan\": count_Manhattan.values, \"Minkowski\": count_Minkowski.values, \n",
    "                                \"Pearson\": count_Pearson,            \"Canberra\": count_Canberra}, index = list(count_Cosine.index))\n",
    "## Add sum row to the end of the dataframe\n",
    "count_Combined.loc['Total',:]= count_Combined.sum(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Process:` Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Values\n",
    "mean_Cosine, mean_Euclidean, mean_Manhattan, mean_Minkowski, mean_Pearson, mean_Canberra = [], [], [], [], [], [] \n",
    "for label in current_Labels: \n",
    "    mean_Cosine.append( data[\"Similarity_Score_Cosine\"].apply(lambda x: x[label]).mean() ) \n",
    "    mean_Euclidean.append( data[\"Similarity_Score_Euclidean\"].apply(lambda x: x[label]).mean() ) \n",
    "    mean_Manhattan.append( data[\"Similarity_Score_Manhattan\"].apply(lambda x: x[label]).mean() ) \n",
    "    mean_Minkowski.append( data[\"Similarity_Score_Minkowski\"].apply(lambda x: x[label]).mean() ) \n",
    "    mean_Pearson.append( data[\"Similarity_Score_Pearson\"].apply(lambda x: x[label]).mean() )  \n",
    "    mean_Canberra.append( data[\"Similarity_Score_Canberra\"].apply(lambda x: x[label]).mean() )  \n",
    "# Combined \n",
    "mean_Combined = pd.DataFrame({\"Cosine\": mean_Cosine,       \"Euclidean\": mean_Euclidean, \n",
    "                              \"Manhattan\": mean_Manhattan, \"Minkowski\": mean_Minkowski, \n",
    "                              \"Pearson\": mean_Pearson,     \"Canberra\": mean_Canberra, \n",
    "                              }, index = list(current_Labels))\n",
    "## Add sum row to the end of the dataframe\n",
    "mean_Combined.loc['Total',:]= mean_Combined.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Process:` Precision, Recall, F1, Support  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = create_Report(\"predicted_labels_Cosine\")['title'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_Cosine = create_Report(\"predicted_labels_Cosine\")   \n",
    "report_Cosine['title'] = ['Cosines: ' + x for x in current_Labels]\n",
    "# Add total row to the end of the dataframe\n",
    "temp = report_Cosine.iloc[:,1:].mean(axis=0) \n",
    "temp = ['Total'] + list (temp)  \n",
    "# Add temp to the end of the dataframe as a row\n",
    "report_Cosine.loc[len(report_Cosine)] = temp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_Minkowski = create_Report(\"predicted_labels_Minkowski\")   \n",
    "report_Minkowski['title'] = ['Minkowski: ' + x for x in current_Labels]\n",
    "# Add total row to the end of the dataframe\n",
    "temp = report_Minkowski.iloc[:,1:].mean(axis=0) \n",
    "temp = ['Total'] + list (temp)  \n",
    "# Add temp to the end of the dataframe as a row\n",
    "report_Minkowski.loc[len(report_Minkowski)] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_Manhattan = create_Report(\"predicted_labels_Manhattan\")   \n",
    "report_Manhattan['title'] = ['Manhattan: ' + x for x in current_Labels]\n",
    "# Add total row to the end of the dataframe\n",
    "temp = report_Manhattan.iloc[:,1:].mean(axis=0) \n",
    "temp = ['Total'] + list (temp)  \n",
    "# Add temp to the end of the dataframe as a row\n",
    "report_Manhattan.loc[len(report_Manhattan)] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_Euclidean = create_Report(\"predicted_labels_Euclidean\")   \n",
    "report_Euclidean['title'] = ['Euclidean: ' + x for x in current_Labels]\n",
    "# Add total row to the end of the dataframe\n",
    "temp = report_Euclidean.iloc[:,1:].mean(axis=0) \n",
    "temp = ['Total'] + list (temp)  \n",
    "# Add temp to the end of the dataframe as a row\n",
    "report_Euclidean.loc[len(report_Euclidean)] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_Pearson = create_Report(\"predicted_labels_Pearson\")   \n",
    "report_Pearson['title'] = ['Pearson: ' + x for x in current_Labels]\n",
    "# Add total row to the end of the dataframe\n",
    "temp = report_Pearson.iloc[:,1:].mean(axis=0) \n",
    "temp = ['Total'] + list (temp)  \n",
    "# Add temp to the end of the dataframe as a row\n",
    "report_Pearson.loc[len(report_Pearson)] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_Canberra = create_Report(\"predicted_labels_Canberra\")   \n",
    "report_Canberra['title'] = ['Canberra: ' + x for x in current_Labels]\n",
    "# Add total row to the end of the dataframe\n",
    "temp = report_Canberra.iloc[:,1:].mean(axis=0) \n",
    "temp = ['Total'] + list (temp)  \n",
    "# Add temp to the end of the dataframe as a row\n",
    "report_Canberra.loc[len(report_Canberra)] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.concat([report_Cosine, report_Minkowski], axis=1) \n",
    "bottom = pd.concat([report_Manhattan, report_Euclidean], axis=1) \n",
    "bottom2 = pd.concat([report_Pearson, report_Canberra], axis=1) \n",
    "combined = pd.concat([top, bottom], axis=0) \n",
    "combined = pd.concat([combined, bottom2], axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Process:` Accuracy, Macro Avg, Weighted Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_2 = extract_summary_metrics(\"predicted_labels_Cosine\")['title'].tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>925.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>925.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title  precision  recall    f1  support\n",
       "0      accuracy        NaN     NaN   NaN      NaN\n",
       "1     macro avg      925.0     NaN   NaN      NaN\n",
       "2  weighted avg        0.8    0.89  0.83    925.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_summary_metrics(\"predicted_labels_Cosine\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_2_Cosine             = extract_summary_metrics(\"predicted_labels_Cosine\") \n",
    "report_2_Cosine['title']    = ['Cosine: ' + x for x in report_2_Cosine['title'] ] \n",
    "report_2_Minkowski          = extract_summary_metrics(\"predicted_labels_Minkowski\") \n",
    "report_2_Minkowski['title'] = ['Minkowski: ' + x for x in report_2_Cosine['title'] ] \n",
    "report_2_Manhattan          = extract_summary_metrics(\"predicted_labels_Manhattan\") \n",
    "report_2_Manhattan['title'] = ['Manhattan: ' + x for x in report_2_Cosine['title'] ] \n",
    "report_2_Euclidean          = extract_summary_metrics(\"predicted_labels_Euclidean\") \n",
    "report_2_Euclidean['title'] = ['Euclidean: ' + x for x in report_2_Cosine['title'] ] \n",
    "report_2_Pearson            = extract_summary_metrics(\"predicted_labels_Pearson\") \n",
    "report_2_Pearson['title']   = ['Pearson: ' + x for x in report_2_Cosine['title'] ] \n",
    "report_2_Canberra           = extract_summary_metrics(\"predicted_labels_Canberra\") \n",
    "report_2_Canberra['title']  = ['Canberra: ' + x for x in report_2_Cosine['title'] ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.concat([report_2_Cosine, report_2_Minkowski], axis=1) \n",
    "bottom = pd.concat([report_2_Manhattan, report_2_Euclidean], axis=1) \n",
    "bottom2 = pd.concat([report_2_Pearson, report_2_Canberra], axis=1) \n",
    "combined_2 = pd.concat([top, bottom], axis=0) \n",
    "combined_2 = pd.concat([combined_2, bottom2], axis=0) \n",
    "combined_2.columns = (['title'] + titles_2 + ['X']) * 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine</th>\n",
       "      <th>Euclidean</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Minkowski</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Canberra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.737207</td>\n",
       "      <td>0.579858</td>\n",
       "      <td>0.042425</td>\n",
       "      <td>0.799796</td>\n",
       "      <td>0.736988</td>\n",
       "      <td>0.001088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.729144</td>\n",
       "      <td>0.576163</td>\n",
       "      <td>0.041937</td>\n",
       "      <td>0.797066</td>\n",
       "      <td>0.728925</td>\n",
       "      <td>0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.733175</td>\n",
       "      <td>0.578010</td>\n",
       "      <td>0.042181</td>\n",
       "      <td>0.798431</td>\n",
       "      <td>0.732956</td>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cosine  Euclidean  Manhattan  Minkowski   Pearson  Canberra\n",
       "positive  0.737207   0.579858   0.042425   0.799796  0.736988  0.001088\n",
       "negative  0.729144   0.576163   0.041937   0.797066  0.728925  0.001085\n",
       "Total     0.733175   0.578010   0.042181   0.798431  0.732956  0.001086"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cosine</th>\n",
       "      <th>Euclidean</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Minkowski</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Canberra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>730.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>925.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>925.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cosine  Euclidean  Manhattan  Minkowski  Pearson  Canberra\n",
       "positive   730.0      730.0      703.0      738.0    730.0     550.0\n",
       "negative   195.0      195.0      222.0      187.0    195.0     375.0\n",
       "Total      925.0      925.0      925.0      925.0    925.0     925.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "      <th>title</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cosines: positive</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.730</td>\n",
       "      <td>136.0</td>\n",
       "      <td>Minkowski: positive</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.750</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cosines: negative</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.940</td>\n",
       "      <td>789.0</td>\n",
       "      <td>Minkowski: negative</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.950</td>\n",
       "      <td>789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.835</td>\n",
       "      <td>462.5</td>\n",
       "      <td>Total</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.850</td>\n",
       "      <td>462.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan: positive</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.640</td>\n",
       "      <td>136.0</td>\n",
       "      <td>Euclidean: positive</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.730</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan: negative</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.910</td>\n",
       "      <td>789.0</td>\n",
       "      <td>Euclidean: negative</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.940</td>\n",
       "      <td>789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.775</td>\n",
       "      <td>462.5</td>\n",
       "      <td>Total</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.835</td>\n",
       "      <td>462.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pearson: positive</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.730</td>\n",
       "      <td>136.0</td>\n",
       "      <td>Canberra: positive</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.490</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson: negative</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.940</td>\n",
       "      <td>789.0</td>\n",
       "      <td>Canberra: negative</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.810</td>\n",
       "      <td>789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.835</td>\n",
       "      <td>462.5</td>\n",
       "      <td>Total</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.650</td>\n",
       "      <td>462.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title  precision  recall     f1  support  \\\n",
       "0    Cosines: positive       0.62    0.88  0.730    136.0   \n",
       "1    Cosines: negative       0.98    0.90  0.940    789.0   \n",
       "2                Total       0.80    0.89  0.835    462.5   \n",
       "0  Manhattan: positive       0.51    0.84  0.640    136.0   \n",
       "1  Manhattan: negative       0.97    0.86  0.910    789.0   \n",
       "2                Total       0.74    0.85  0.775    462.5   \n",
       "0    Pearson: positive       0.62    0.88  0.730    136.0   \n",
       "1    Pearson: negative       0.98    0.90  0.940    789.0   \n",
       "2                Total       0.80    0.89  0.835    462.5   \n",
       "\n",
       "                 title  precision  recall     f1  support  \n",
       "0  Minkowski: positive      0.650   0.890  0.750    136.0  \n",
       "1  Minkowski: negative      0.980   0.920  0.950    789.0  \n",
       "2                Total      0.815   0.905  0.850    462.5  \n",
       "0  Euclidean: positive      0.620   0.880  0.730    136.0  \n",
       "1  Euclidean: negative      0.980   0.900  0.940    789.0  \n",
       "2                Total      0.800   0.890  0.835    462.5  \n",
       "0   Canberra: positive      0.330   0.920  0.490    136.0  \n",
       "1   Canberra: negative      0.980   0.680  0.810    789.0  \n",
       "2                Total      0.655   0.800  0.650    462.5  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "      <th>X</th>\n",
       "      <th>title</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cosine: accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minkowski: Cosine: accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cosine: macro avg</td>\n",
       "      <td>925.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minkowski: Cosine: macro avg</td>\n",
       "      <td>925.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cosine: weighted avg</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>925.0</td>\n",
       "      <td>Minkowski: Cosine: weighted avg</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan: Cosine: accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Euclidean: Cosine: accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan: Cosine: macro avg</td>\n",
       "      <td>925.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Euclidean: Cosine: macro avg</td>\n",
       "      <td>925.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan: Cosine: weighted avg</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.77</td>\n",
       "      <td>925.0</td>\n",
       "      <td>Euclidean: Cosine: weighted avg</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pearson: Cosine: accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canberra: Cosine: accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pearson: Cosine: macro avg</td>\n",
       "      <td>925.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canberra: Cosine: macro avg</td>\n",
       "      <td>925.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pearson: Cosine: weighted avg</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>925.0</td>\n",
       "      <td>Canberra: Cosine: weighted avg</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.65</td>\n",
       "      <td>925.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  accuracy  macro avg  weighted avg      X  \\\n",
       "0                 Cosine: accuracy       NaN        NaN           NaN    NaN   \n",
       "1                Cosine: macro avg    925.00        NaN           NaN    NaN   \n",
       "2             Cosine: weighted avg      0.80       0.89          0.83  925.0   \n",
       "0      Manhattan: Cosine: accuracy       NaN        NaN           NaN    NaN   \n",
       "1     Manhattan: Cosine: macro avg    925.00        NaN           NaN    NaN   \n",
       "2  Manhattan: Cosine: weighted avg      0.74       0.85          0.77  925.0   \n",
       "0        Pearson: Cosine: accuracy       NaN        NaN           NaN    NaN   \n",
       "1       Pearson: Cosine: macro avg    925.00        NaN           NaN    NaN   \n",
       "2    Pearson: Cosine: weighted avg      0.80       0.89          0.83  925.0   \n",
       "\n",
       "                             title  accuracy  macro avg  weighted avg      X  \n",
       "0      Minkowski: Cosine: accuracy       NaN        NaN           NaN    NaN  \n",
       "1     Minkowski: Cosine: macro avg    925.00        NaN           NaN    NaN  \n",
       "2  Minkowski: Cosine: weighted avg      0.81       0.90          0.85  925.0  \n",
       "0      Euclidean: Cosine: accuracy       NaN        NaN           NaN    NaN  \n",
       "1     Euclidean: Cosine: macro avg    925.00        NaN           NaN    NaN  \n",
       "2  Euclidean: Cosine: weighted avg      0.80       0.89          0.83  925.0  \n",
       "0       Canberra: Cosine: accuracy       NaN        NaN           NaN    NaN  \n",
       "1      Canberra: Cosine: macro avg    925.00        NaN           NaN    NaN  \n",
       "2   Canberra: Cosine: weighted avg      0.66       0.80          0.65  925.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `Checkpoint` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "# Save the entire session\n",
    "dill.dump_session('session_A.pkl')  \n",
    "# Actialize the session\n",
    "#dill.load_session('session.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
